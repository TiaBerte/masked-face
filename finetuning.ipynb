{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhu-IvtmuU97"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TiaBerte/masked-face/blob/main/finetuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs = 'C:/Users/Mattia/Desktop/MLFW/pairs.txt'\n",
        "with open(pairs, 'r') as f:\n",
        "    p = f.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv('./celeb_skin_train.csv')\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "for i in range(len(df)):\n",
        "    x = df['Skin_B'].iloc[i]\n",
        "    y = df['Skin_G'].iloc[i]\n",
        "    z = df['Skin_R'].iloc[i]\n",
        "    ax.scatter(x, y, z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2386"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(8)\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8698"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.dropna()\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Skin_B</th>\n",
              "      <th>Skin_G</th>\n",
              "      <th>Skin_R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AJ_Lamas</td>\n",
              "      <td>129.085133</td>\n",
              "      <td>157.385524</td>\n",
              "      <td>197.401812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aaron_Eckhart</td>\n",
              "      <td>112.070054</td>\n",
              "      <td>131.937383</td>\n",
              "      <td>174.103971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aaron_Guiel</td>\n",
              "      <td>115.627017</td>\n",
              "      <td>132.213654</td>\n",
              "      <td>177.165214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aaron_Peirsol</td>\n",
              "      <td>139.197227</td>\n",
              "      <td>161.051394</td>\n",
              "      <td>212.479727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aaron_Sorkin</td>\n",
              "      <td>76.050987</td>\n",
              "      <td>94.290196</td>\n",
              "      <td>153.007661</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Name      Skin_B      Skin_G      Skin_R\n",
              "0       AJ_Lamas  129.085133  157.385524  197.401812\n",
              "1  Aaron_Eckhart  112.070054  131.937383  174.103971\n",
              "2    Aaron_Guiel  115.627017  132.213654  177.165214\n",
              "3  Aaron_Peirsol  139.197227  161.051394  212.479727\n",
              "4   Aaron_Sorkin   76.050987   94.290196  153.007661"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grouped = df.groupby(by='Name').mean().reset_index()\n",
        "grouped.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2386"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(grouped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'Skin'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[1;32mc:\\Users\\Mattia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[1;32mc:\\Users\\Mattia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Mattia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Skin'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Mattia\\Documents\\GitHub\\masked-face\\finetuning.ipynb Cell 4\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mSkin\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m r : \u001b[39mtuple\u001b[39m(r[\u001b[39m'\u001b[39m\u001b[39mSkin_B\u001b[39m\u001b[39m'\u001b[39m], r[\u001b[39m'\u001b[39m\u001b[39mSkin_G\u001b[39m\u001b[39m'\u001b[39m], r[\u001b[39m'\u001b[39m\u001b[39mSkin_R\u001b[39m\u001b[39m'\u001b[39m]))\n",
            "File \u001b[1;32mc:\\Users\\Mattia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3506\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   3505\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3506\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[0;32m   3507\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3508\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
            "File \u001b[1;32mc:\\Users\\Mattia\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[1;31mKeyError\u001b[0m: 'Skin'"
          ]
        }
      ],
      "source": [
        "df['Skin'].apply(lambda r : tuple(r['Skin_B'], r['Skin_G'], r['Skin_R']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!sudo apt-get install git-lfs\n",
        "!git-lfs clone https://github.com/TiaBerte/masked-face.git\n",
        "%cd masked-face"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "H7yNytZAuQ7T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from barlowTwins import BarlowTwins\n",
        "from utils import adjust_learning_rate, load_state_dict, get_mean_and_std, LARS\n",
        "from pathlib import Path\n",
        "import argparse\n",
        "import json\n",
        "import sys\n",
        "import time\n",
        "from torch import nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataload import MaskedFaceDataset\n",
        "import argparse\n",
        "\n",
        "path = './dataset/'\n",
        "train_path = path + 'train/'\n",
        "val_path = path + 'val/'\n",
        "\n",
        "train_set = MaskedFaceDataset(train_path)\n",
        "val_set = MaskedFaceDataset(val_path)\n",
        "\n",
        "num_workers = 2\n",
        "size_batch_train = 64\n",
        "size_batch_val = 2 * size_batch_train\n",
        "\n",
        "loader_train = DataLoader(train_set, batch_size=size_batch_train, \n",
        "                                           shuffle=True, \n",
        "                                           pin_memory=True, \n",
        "                                           num_workers=num_workers)\n",
        "\n",
        "loader_val = DataLoader(val_set, batch_size=size_batch_val, \n",
        "                                         shuffle=False,\n",
        "                                         num_workers=num_workers)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZQyi4-icuQ7Y"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=8631, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"Train = 2397\n",
        "val = 300\n",
        "Test = 300\n",
        "\"\"\"\n",
        "\n",
        "N_IDENTITY = 8631\n",
        "PATH = './'\n",
        "model = resnet50(num_classes=N_IDENTITY)#False)\n",
        "load_state_dict(model, PATH+'weights/resnet50_ft_weight.pkl')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device=device)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucerIxftuQ7a"
      },
      "source": [
        "**PARSER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "n14f6iciuQ7c"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def get_args_parser():\n",
        "    \n",
        "    parser = argparse.ArgumentParser(description='Barlow Twins Training')\n",
        "    #parser.add_argument('data', type=Path, metavar='DIR',\n",
        "    #                help='path to dataset')\n",
        "    parser.add_argument('--workers', default=8, type=int, metavar='N',\n",
        "                    help='number of data loader workers')\n",
        "    parser.add_argument('--epochs', default=1000, type=int, metavar='N',\n",
        "                    help='number of total epochs to run')\n",
        "    parser.add_argument('--batch-size', default=2048, type=int, metavar='N',\n",
        "                    help='mini-batch size')\n",
        "    parser.add_argument('--learning-rate-weights', default=0.2, type=float, metavar='LR',\n",
        "                    help='base learning rate for weights')\n",
        "    parser.add_argument('--learning-rate-biases', default=0.0048, type=float, metavar='LR',\n",
        "                    help='base learning rate for biases and batch norm parameters')\n",
        "    parser.add_argument('--weight-decay', default=1e-6, type=float, metavar='W',\n",
        "                    help='weight decay')\n",
        "    parser.add_argument('--lambd', default=0.0051, type=float, metavar='L',\n",
        "                    help='weight on off-diagonal terms')\n",
        "    parser.add_argument('--projector', default='8192-8192-8192', type=str)\n",
        "                    #metavar='MLP', help='projector MLP')\n",
        "    parser.add_argument('--print-freq', default=100, type=int, metavar='N',\n",
        "                    help='print frequency')\n",
        "    parser.add_argument('--checkpoint-dir', default='./checkpoint/', type=Path,\n",
        "                    metavar='DIR', help='path to checkpoint directory')\n",
        "    parser.add_argument('--backbone_lr', default=0, type=float, \n",
        "                    help='Learning rate used for fine tuning the backbone, disabled by default')\n",
        "\n",
        "    return parser\n",
        "\n",
        "\n",
        "def main_worker(args):\n",
        "    PATH = './'\n",
        "    \n",
        "    model = BarlowTwins(args)\n",
        "    load_state_dict(model, PATH+'weights/resnet50_ft_weight.pkl')\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device=device)\n",
        "\n",
        "    param_weights = []\n",
        "    param_biases = []\n",
        "    for param in model.parameters():\n",
        "        if param.ndim == 1:\n",
        "            param_biases.append(param)\n",
        "        else:\n",
        "            param_weights.append(param)\n",
        "\n",
        "    parameters = [{'params': param_weights}, {'params': param_biases}]\n",
        "\n",
        "    optimizer = LARS(parameters, lr=0.001, weight_decay=args.weight_decay,\n",
        "                     weight_decay_filter=True,\n",
        "                     lars_adaptation_filter=True)\n",
        "\n",
        "    # automatically resume from checkpoint if it exists\n",
        "    if (args.checkpoint_dir / 'checkpoint.pth').is_file():\n",
        "        ckpt = torch.load(args.checkpoint_dir / 'checkpoint.pth',\n",
        "                          map_location='cpu')\n",
        "        start_epoch = ckpt['epoch']\n",
        "        model.load_state_dict(ckpt['model'])\n",
        "        optimizer.load_state_dict(ckpt['optimizer'])\n",
        "    else:\n",
        "        start_epoch = 0\n",
        "\n",
        "    start_time = time.time()\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "    step = 0\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        #for step, ((y1, y2), _) in enumerate(loader_train, start=epoch * len(loader_train)):\n",
        "        data_bar = tqdm(loader_train, desc=f\"Train Epoch {epoch}\")\n",
        "        for img_1, img_2 in data_bar:\n",
        "            step += 1\n",
        "            #y1 = y1.cuda(gpu, non_blocking=True)\n",
        "            #y2 = y2.cuda(gpu, non_blocking=True)\n",
        "            adjust_learning_rate(args, optimizer, loader_train, step)\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                loss = model.forward(img_1, img_2)\n",
        "            \n",
        "            optimizer.step()\n",
        "            #scaler.scale(loss).backward()\n",
        "            #scaler.step(optimizer)\n",
        "            #scaler.update()\n",
        "            if step % args.print_freq == 0:\n",
        "                if args.rank == 0:\n",
        "                    stats = dict(epoch=epoch, step=step,\n",
        "                                 lr_weights=optimizer.param_groups[0]['lr'],\n",
        "                                 lr_biases=optimizer.param_groups[1]['lr'],\n",
        "                                 loss=loss.item(),\n",
        "                                 time=int(time.time() - start_time))\n",
        "                    print(json.dumps(stats))\n",
        "        if args.rank == 0:\n",
        "            # save checkpoint\n",
        "            state = dict(epoch=epoch + 1, model=model.state_dict(),\n",
        "                         optimizer=optimizer.state_dict())\n",
        "            torch.save(state, args.checkpoint_dir / 'checkpoint.pth')\n",
        "    if args.rank == 0:\n",
        "        # save final model\n",
        "        torch.save(model.module.backbone.state_dict(),\n",
        "                   args.checkpoint_dir / 'resnet50.pth')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Train Epoch 0:   0%|          | 0/38 [00:00<?, ?it/s]"
          ]
        }
      ],
      "source": [
        "from barlowTwins import BarlowTwins\n",
        "\n",
        "PATH = './'\n",
        "args_parser = get_args_parser()\n",
        "args = args_parser.parse_args([])\n",
        "\n",
        "model = BarlowTwins(args)\n",
        "load_state_dict(model, PATH+'weights/resnet50_ft_weight.pkl')\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#model.to(device=device)\n",
        "\n",
        "param_weights = []\n",
        "param_biases = []\n",
        "for param in model.parameters():\n",
        "        if param.ndim == 1:\n",
        "            param_biases.append(param)\n",
        "        else:\n",
        "            param_weights.append(param)\n",
        "\n",
        "parameters = [{'params': param_weights}, {'params': param_biases}]\n",
        "    \n",
        "optimizer = LARS(parameters, lr=0.001, weight_decay=args.weight_decay,\n",
        "                     weight_decay_filter=True,\n",
        "                     lars_adaptation_filter=True)\n",
        "\n",
        "    # automatically resume from checkpoint if it exists\n",
        "if (args.checkpoint_dir / 'checkpoint.pth').is_file():\n",
        "        ckpt = torch.load(args.checkpoint_dir / 'checkpoint.pth',\n",
        "                          map_location='cpu')\n",
        "        start_epoch = ckpt['epoch']\n",
        "        model.load_state_dict(ckpt['model'])\n",
        "        optimizer.load_state_dict(ckpt['optimizer'])\n",
        "else:\n",
        "        start_epoch = 0\n",
        "\n",
        "start_time = time.time()\n",
        "#scaler = torch.cuda.amp.GradScaler()\n",
        "step = 0\n",
        "for epoch in range(start_epoch, args.epochs):\n",
        "        #for step, ((y1, y2), _) in enumerate(loader_train, start=epoch * len(loader_train)):\n",
        "        data_bar = tqdm(loader_train, desc=f\"Train Epoch {epoch}\")\n",
        "        for img_1, img_2 in data_bar:\n",
        "            step += 1\n",
        "            #y1 = y1.cuda(gpu, non_blocking=True)\n",
        "            #y2 = y2.cuda(gpu, non_blocking=True)\n",
        "            adjust_learning_rate(args, optimizer, loader_train, step)\n",
        "            optimizer.zero_grad()\n",
        "            #with torch.cuda.amp.autocast():\n",
        "            loss = model.forward(img_1, img_2)\n",
        "            #scaler.scale(loss).backward()\n",
        "            loss.backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            if step % args.print_freq == 0:\n",
        "                if args.rank == 0:\n",
        "                    stats = dict(epoch=epoch, step=step,\n",
        "                                 lr_weights=optimizer.param_groups[0]['lr'],\n",
        "                                 lr_biases=optimizer.param_groups[1]['lr'],\n",
        "                                 loss=loss.item(),\n",
        "                                 time=int(time.time() - start_time))\n",
        "                    print(json.dumps(stats))\n",
        "        if args.rank == 0:\n",
        "            # save checkpoint\n",
        "            state = dict(epoch=epoch + 1, model=model.state_dict(),\n",
        "                         optimizer=optimizer.state_dict())\n",
        "            torch.save(state, args.checkpoint_dir / 'checkpoint.pth')\n",
        "if args.rank == 0:\n",
        "        # save final model\n",
        "        torch.save(model.module.backbone.state_dict(),\n",
        "                   args.checkpoint_dir / 'resnet50.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ResNet:\n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". ",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Mattia\\Documents\\GitHub\\masked-face\\finetuning.ipynb Cell 8'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000016?line=2'>3</a>\u001b[0m       obj \u001b[39m=\u001b[39m f\u001b[39m.\u001b[39mread()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000016?line=4'>5</a>\u001b[0m weights \u001b[39m=\u001b[39m {key: torch\u001b[39m.\u001b[39mfrom_numpy(arr) \u001b[39mfor\u001b[39;00m key, arr \u001b[39min\u001b[39;00m pickle\u001b[39m.\u001b[39mloads(obj, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000016?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mbackbone\u001b[39m.\u001b[39;49mload_state_dict(weights)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1482\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattia/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/nn/modules/module.py?line=1476'>1477</a>\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattia/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/nn/modules/module.py?line=1477'>1478</a>\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattia/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/nn/modules/module.py?line=1478'>1479</a>\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattia/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/nn/modules/module.py?line=1480'>1481</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Mattia/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/nn/modules/module.py?line=1481'>1482</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattia/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/nn/modules/module.py?line=1482'>1483</a>\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   <a href='file:///c%3A/Users/Mattia/AppData/Local/Programs/Python/Python39/lib/site-packages/torch/nn/modules/module.py?line=1483'>1484</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ResNet:\n\tUnexpected key(s) in state_dict: \"fc.weight\", \"fc.bias\". "
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "with open(PATH+'weights/resnet50_ft_weight.pkl', 'rb') as f:  \n",
        "      obj = f.read()\n",
        "\n",
        "weights = {key: torch.from_numpy(arr) for key, arr in pickle.loads(obj, encoding='latin1').items()}\n",
        "model.backbone.load_state_dict(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "args_parser = get_args_parser()\n",
        "args = args_parser.parse_args([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bWsgh0RAuQ7f"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'unexpected key \"layer4.1.bn3.bias\" in state_dict'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\Mattia\\Documents\\GitHub\\masked-face\\finetuning.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000007?line=0'>1</a>\u001b[0m main_worker(args)\n",
            "\u001b[1;32mc:\\Users\\Mattia\\Documents\\GitHub\\masked-face\\finetuning.ipynb Cell 7'\u001b[0m in \u001b[0;36mmain_worker\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000006?line=32'>33</a>\u001b[0m PATH \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mC:/Users/Mattia/Documents/GitHub/masked-face/\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000006?line=34'>35</a>\u001b[0m model \u001b[39m=\u001b[39m BarlowTwins(args)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000006?line=35'>36</a>\u001b[0m load_state_dict(model, PATH\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mweights/resnet50_ft_weight.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000006?line=36'>37</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Mattia/Documents/GitHub/masked-face/finetuning.ipynb#ch0000006?line=37'>38</a>\u001b[0m model\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39mdevice)\n",
            "File \u001b[1;32mc:\\Users\\Mattia\\Documents\\GitHub\\masked-face\\utils.py:31\u001b[0m, in \u001b[0;36mload_state_dict\u001b[1;34m(model, fname)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattia/Documents/GitHub/masked-face/utils.py?line=27'>28</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mWhile copying the parameter named \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, whose dimensions in the model are \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and whose \u001b[39m\u001b[39m'\u001b[39m\\\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattia/Documents/GitHub/masked-face/utils.py?line=28'>29</a>\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mdimensions in the checkpoint are \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name, own_state[name]\u001b[39m.\u001b[39msize(), param\u001b[39m.\u001b[39msize()))\n\u001b[0;32m     <a href='file:///c%3A/Users/Mattia/Documents/GitHub/masked-face/utils.py?line=29'>30</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> <a href='file:///c%3A/Users/Mattia/Documents/GitHub/masked-face/utils.py?line=30'>31</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39munexpected key \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m in state_dict\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(name))\n",
            "\u001b[1;31mKeyError\u001b[0m: 'unexpected key \"layer4.1.bn3.bias\" in state_dict'"
          ]
        }
      ],
      "source": [
        "main_worker(args)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "finetuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b5edaccf816b48d6be57fb0c23d14db5fa6197f9f7c932e4e0efd2413c237c71"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
